## Methods {#sec:methods}

PhenoPLIER is a framework that combines various computational approaches to integrate gene-trait associations and drug-induced transcriptional responses with groups of functionally-related genes, known as gene modules or latent variables (LVs).
Gene-trait associations are calculated using the PrediXcan family of methods, while latent variables are inferred by the MultiPLIER models applied to large gene expression compendia.
PhenoPLIER offers three main components: 

1) A regression model to calculate an LV-trait association.
2) A consensus clustering approach applied to the latent space to identify shared and distinct transcriptomic properties between traits.
3) An interpretable, LV-based drug repurposing framework.

The details of these methods are provided below.

$$LV-trait association = \beta_0 + \beta_1 \cdot LV$$ {#lv-trait}

$$\text{where}$$

- LV is the latent variable representing gene expression patterns.
- $\beta_0$ is the intercept term.
- $\beta_1$ is the coefficient of the LV.


### The PrediXcan family of methods for gene-based associations {#sec:methods:predixcan}

We utilized Summary-PrediXcan (S-PrediXcan) (Barbeira et al., 2018) and Summary-MultiXcan (S-MultiXcan) (Barbeira et al., 2019) as the gene-based statistical approaches, which are part of the PrediXcan family of methods (Gamazon et al., 2015).
These approaches are collectively known as TWAS (transcription-wide association studies).
S-PrediXcan, the summary-based version of PrediXcan, calculates the univariate association between a trait and a gene's predicted expression in a single tissue.
In contrast, S-MultiXcan, the summary-based version of MultiXcan, calculates the joint association between a gene's predicted expression in all tissues and a trait.
S-PrediXcan and S-MultiXcan only require GWAS summary statistics instead of individual-level genotype and phenotype data.

$$ S-PrediXcan: \quad \hat{y} = X \beta + Z b + \epsilon $$ {#eq1}

$$ S-MultiXcan: \quad Y = X \beta + Z b + \epsilon $$ {#eq2}

Here, we provide a brief overview of the TWAS methods that will be necessary to understand our regression framework later (for more detailed information, please refer to the cited articles).
In the following discussion, $\mathbf{y}$ refers to a vector of traits for $n$ individuals that has been centered for convenience, eliminating the need for an intercept.
Additionally, $\tilde{\mathbf{t}}_l = \sum_{a \in \mathrm{model}_l} w_{a}^{l} X_{a}$ represents the predicted expression of a gene for all individuals in tissue $l$, where $X_a$ denotes the genotype of SNP $a$ and $w_{a}$ represents its weight in the tissue prediction model $l$.
Furthermore, $\mathbf{t}_l$ is the standardized version of $\tilde{\mathbf{t}}_l$, with a mean of zero and a standard deviation of one.

$$
\mathbf{y}: \text{vector of traits for $n$ individuals}
$$

$$
\tilde{\mathbf{t}}_l = \sum_{a \in \mathrm{model}_l} w_{a}^{l} X_{a}: \text{predicted expression of a gene for all individuals in tissue $l$}
$$

$$
\mathbf{t}_l: \text{standardized version of $\tilde{\mathbf{t}}_l$ with mean equal to zero and standard deviation equal to one}
$$

S-PrediXcan is the summary version of PrediXcan.
PrediXcan models the trait as a linear function of the gene's expression on a single tissue using the univariate model:

$$
\mathbf{y} = \mathbf{t}_l \gamma_l + \bm{\epsilon}_l,
$$ {#eq:predixcan}

where $\hat{\gamma}_l$ is the estimated effect size or regression coefficient, and $\bm{\epsilon}_l$ are the error terms with variance $\sigma_{\epsilon}^{2}$.
The significance of the association is assessed by computing the $z$-score $\hat{z}_{l}=\hat{\gamma}_l / \mathrm{se}(\hat{\gamma}_l)$ for a gene's tissue model $l$.
PrediXcan requires individual-level data to fit this model, whereas S-PrediXcan approximates PrediXcan $z$-scores using only GWAS summary statistics with the expression:

$$
\hat{z}_{l} \approx \sum_{a \in model_{l}} w_a^l \frac{\hat{\sigma}_a}{\hat{\sigma}_l} \frac{\hat{\beta}_a}{\mathrm{se}(\hat{\beta}_a)},
$$ {#eq:spredixcan}

where $\hat{\sigma}_a$ is the variance of SNP $a$, $\hat{\sigma}_l$ is the variance of the predicted expression of a gene in tissue $l$, and $\hat{\beta}_a$ is the estimated effect size of SNP $a$ from the GWAS.
In these Transcriptome-Wide Association Studies (TWAS) methods, the genotype variances and covariances are always estimated using the Genotype-Tissue Expression project (GTEx v8) as the reference panel.
Since S-PrediXcan provides tissue-specific directions of effects (for instance, whether a higher or lower predicted expression of a gene confers more or less disease risk), we used the $z$-scores in our drug repurposing approach (described below).

S-MultiXcan is the summary version of MultiXcan, which is more powerful than PrediXcan in detecting gene-trait associations but does not provide the direction of effects.
The main output of MultiXcan is the p-value obtained with an F-test in the multiple tissue model:

$$
\begin{split}
\mathbf{y} & = \sum_{l=1}^{p} \mathbf{t}_l g_l + \mathbf{e} \\
& = \mathbf{T} \mathbf{g} + \mathbf{e},
\end{split}
$$ {#eq:multixcan}

Here, $\mathbf{T}$ is a matrix with $p$ columns $\mathbf{t}_l$, $\hat{g}_l$ is the estimated effect size for the predicted gene expression in tissue $l$, and $\mathbf{e}$ are the error terms with variance $\sigma_{e}^{2}$.
Due to the high correlation between predicted expression values for a gene across different tissues, MultiXcan uses the principal components (PCs) of $\mathbf{T}$ to avoid collinearity issues.
S-MultiXcan derives joint regression estimates in Equation (@eq:multixcan) using the marginal estimates from S-PrediXcan in Equation (@eq:spredixcan).
Under the null hypothesis of no association, the significance of the association in S-MultiXcan is estimated with:

$$
\begin{split}
\frac{\hat{\mathbf{g}}^{\top} (\mathbf{T}^{\top}\mathbf{T}) \hat{\mathbf{g}}}{\sigma_{e}^{2}} & \approx \bm{\hat{\gamma}}^{\top} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \left(\frac{\mathbf{T}^{\top} \mathbf{T}}{n-1}\right)^{-1} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \bm{\hat{\gamma}} \\
& = \hat{\mathbf{z}}^{\top} Cor(\mathbf{T})^{-1} \hat{\mathbf{z}},
\end{split}
$$ {#eq:smultixcan}

Here, $\hat{\mathbf{z}}$ is a vector with $p$ z-scores for each tissue available for the gene, and $Cor(\mathbf{T})$ is the autocorrelation matrix of $\mathbf{T}$.
Since $\mathbf{T}^{\top}\mathbf{T}$ is singular for many genes, S-MultiXcan computes the pseudo-inverse $Cor(\mathbf{T})^{+}$ using the top $k$ PCs, and thus $\hat{\mathbf{z}}^{\top} Cor(\mathbf{T})^{+} \hat{\mathbf{z}} \sim \chi_k^2$.
To arrive at this expression, S-MultiXcan uses the conservative approximation $\sigma_{e}^{2} \approx \sigma_{\epsilon}^{2}$.
Additionally, $Cor(\mathbf{T})$ is estimated using a global genotype covariance matrix, while marginal z-scores in Equation (@eq:spredixcan) are approximated using tissue-specific genotype covariances.
Although S-MultiXcan yields highly concordant estimates compared with MultiXcan, results are not perfectly correlated across genes.
These differences are crucial for our LV-based regression model when computing the gene-gene correlation matrix.
We utilized S-MultiXcan results for our LV-based regression model and cluster analyses of traits.


### TWAS resources {#sec:methods:twas}

We used two large TWAS resources from different cohorts for discovery and replication, all obtained from European ancestries.
PhenomeXcan [@doi:10.1126/sciadv.aba2083], our discovery cohort, provides results on 4,091 traits across different categories.
Supplementary Data 1 has all the details about the included GWAS, sample size and disease/trait categories.
In PhenomeXcan, these publicly available GWAS summary statistics were used to compute
1) gene-based associations with the PrediXcan family of methods (described before), and
2) a posterior probability of colocalization between GWAS loci and *cis*-eQTL with fastENLOC [@doi:10.1126/sciadv.aba2083; @doi:10.1016/j.ajhg.2020.11.012].
We refer to the matrix of $z$-scores from S-PrediXcan (Equation (@eq:spredixcan)) across $q$ traits and $m$ genes in tissue $t$ as $\mathbf{M}^{t} \in \mathbb{R}^{q \times m}$.
As explained later, matrices $\mathbf{M}^{t}$ were used in our LV-based drug repurposing framework since they provide direction of effects.
The S-MultiXcan results (22,515 gene associations across 4,091 traits) were used in our LV-based regression framework and our cluster analyses of traits.
For the cluster analyses, we used the $p$-values converted to $z$-scores: $\mathbf{M}=\Phi^{-1}(1 - p/2)$, where $\Phi^{-1}$ is the probit function.
Higher $z$-scores correspond to stronger associations.

Our discovery cohort was eMERGE [@doi:10.1038/gim.2013.72], where the same TWAS methods were run on 309 phecodes [@doi:10.1101/2021.10.21.21265225] across different categories (more information about traits are available in [@doi:10.1101/2021.10.21.21265225]).
We used these results to replicate the associations found with our LV-based regression framework in PhenomeXcan.


### MultiPLIER and Pathway-level information extractor (PLIER) {#sec:methods:multiplier}

MultiPLIER [@doi:10.1016/j.cels.2019.04.003] extracts patterns of co-expressed genes from recount2 [@doi:10.1038/nbt.3838], a large gene expression dataset, without including GTEx samples.
The approach applies the Pathway-Level Information Extractor method (PLIER) [@doi:10.1038/s41592-019-0456-1], which performs unsupervised learning using prior knowledge (canonical pathways) to reduce technical noise.
PLIER uses a matrix factorization approach that deconvolutes gene expression data into a set of latent variables (LV), where each LV represents a gene module.
The MultiPLIER models reduced the dimensionality in recount2 to 987 LVs.

$$
\text{Symbols:}\\
\text{LV} - \text{Latent Variable}
$$

Given a gene expression dataset $\mathbf{Y}^{m \times c}$ with $m$ genes and $c$ experimental conditions and a prior knowledge matrix $\mathbf{C} \in \{0,1\}^{m \times p}$ for $p$ MSigDB pathways (so that $\mathbf{C}_{ij} = 1$ if gene $i$ belongs to pathway $j$), PLIER finds $\mathbf{U}$, $\mathbf{Z}$, and $\mathbf{B}$ minimizing

$$
||\mathbf{Y} - \mathbf{Z}\mathbf{B}||^{2}_{F} + \lambda_1 ||\mathbf{Z} - \mathbf{C}\mathbf{U}||^{2}_{F} + \lambda_2 ||\mathbf{B}||^{2}_{F} + \lambda_3 ||\mathbf{U}||_{L^1}
$$ {#eq:met:plier_func}

subject to $\mathbf{U}>0, \mathbf{Z}>0$; $\mathbf{Z}^{m \times l}$ are the gene loadings with $l$ latent variables, $\mathbf{B}^{l \times c}$ is the latent space for $c$ conditions, $\mathbf{U}^{p \times l}$ specifies which of the $p$ prior-information pathways in $\mathbf{C}$ are represented for each latent variable, and $\lambda_i$ are different regularization parameters used in the training step.
$\mathbf{Z}$ is a low-dimensional representation of the gene space where each latent variable aligns as much as possible to prior knowledge, and it might represent either a known or novel gene module (i.e., a meaningful biological pattern) or noise.

For our drug repurposing and cluster analyses, we utilized a model to project gene-trait associations (obtained from TWAS) and gene-drug associations (obtained from LINCS L1000) into a low-dimensional gene module space.
Specifically, TWAS associations $\mathbf{M}$, derived from either S-PrediXcan or S-MultiXcan, were projected using the following equation:

$$
\hat{\mathbf{M}} = (\mathbf{Z}^{\top} \mathbf{Z} + \lambda_{2} \mathbf{I})^{-1} \mathbf{Z}^{\top} \mathbf{M},
$$ {#eq:proj}

Here, $\hat{\mathbf{M}}^{l \times q}$ represents a matrix where traits are expressed in terms of gene modules rather than individual genes.
Subsequently, we applied the same methodology to project drug-induced transcriptional profiles from LINCS L1000, enabling us to characterize drugs based on gene modules.


### Regression model for LV-trait associations {#sec:methods:reg}

We adapted the gene-set analysis framework from MAGMA [@doi:10.1371/journal.pcbi.1004219] to TWAS.
We used a competitive test to predict gene-trait associations from TWAS using gene weights from an LV, testing whether top-weighted genes for an LV are more strongly associated with the phenotype than other genes with relatively small or zero weights.
Thus, we fit the model

$$
\mathbf{m}=\beta_{0} + \mathbf{s} \beta_{s} + \sum_{i} \mathbf{x}_{i} \beta_{i} + \bm{\epsilon},
$$ {#eq:reg:model}

In this study, we utilized a vector $\mathbf{m}$ representing S-MultiXcan gene $p$-values for a specific trait, which have undergone a $-log_{10}$ transformation.
Additionally, we incorporated a binary indicator vector $\mathbf{s}$ where $s_{\ell}=1$ denotes the top 1% of genes with the largest loadings for latent variable (LV) $\ell$ from matrix $\mathbf{Z}_{\ell}$.
The vector $\mathbf{x}_{i}$ was included as a gene property covariate, while effect sizes $\beta$ were determined (with $\beta_{0}$ serving as the intercept).
Error terms were represented by vector $\bm{\epsilon}$ following a multivariate normal distribution (MVN) with a mean of 0 and variance $\sigma^{2}$, where the matrix $\mathbf{R}$ encapsulated gene correlations.

$$
\mathbf{m} = \begin{bmatrix} m_1 \\ m_2 \\ \vdots \\ m_n \end{bmatrix} \quad
\mathbf{s} = \begin{bmatrix} s_1 \\ s_2 \\ \vdots \\ s_n \end{bmatrix} \quad
\mathbf{x}_{i} \quad
\beta \quad
\bm{\epsilon} \sim \mathrm{MVN}(0, \sigma^{2} \math

The model tests the null hypothesis $\beta_{s} = 0$ against the one-sided hypothesis $\beta_{s} > 0$.
Therefore, $\beta_{s}$ reflects the difference in trait associations between genes that are part of latent variable $\ell$ and genes outside of it.
Following the MAGMA framework, we used two gene properties as covariates: 

1) *gene size*, defined as the number of principal components (PCs) retained in S-MultiXcan, and 

2) *gene density*, defined as the ratio of the number of PCs to the number of tissues available.

$$\text{$\beta_{s}$}$$

$$\text{latent variable ($\ell$)}$$

$$\text{principal components (PCs)}$$

Since the error terms $\bm{\epsilon}$ could be correlated, we cannot assume they have independent normal distributions as in a standard linear regression model.
In the PrediXcan family of methods, the predicted expression of a pair of genes could be correlated if they share eQTLs or if these are in LD (Gamazon et al., 2019).
Therefore, we used a generalized least squares approach to account for these correlations.
The gene-gene correlation matrix $\mathbf{R}$ was approximated by computing the correlations between the model sum of squares (SSM) for each pair of genes under the null hypothesis of no association.
These correlations are derived from the individual-level MultiXcan model (Equation (1)), where the predicted expression matrix $\mathbf{T}_{i} \in \mathbb{R}^{n \times p_i}$ of a gene $i$ across $p_i$ tissues is projected into its top $k_i$ principal components (PCs), resulting in matrix $\mathbf{P}_{i} \in \mathbb{R}^{n \times k_i}$.
From the MAGMA framework, we know that the SSM for each gene is proportional to $\mathbf{y}^{\top} \mathbf{P}_{i} \mathbf{P}_{i}^{\top} \mathbf{y$.
Under the null hypothesis of no association, the covariances between the SSM of genes $i$ and $j$ are therefore given by $2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})$.
The standard deviations of each SSM are given by $\sqrt{2 \times k_{i}} \times (n - 1)$.
Therefore, the correlation between the SSMs for genes $i$ and $j$ can be written as follows:

$$
\begin{split}
\mathbf{R}_{ij} & = \frac{2 \times \mathrm{Tr}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}} \times (n - 1)^2} \\
& = \frac{2 \times \mathrm{Tr}(Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \times Cor(\mathbf{P}_{j}, \mathbf{P}_{i}))}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}}},
\end{split}
$$

where columns $\mathbf{P}$ are standardized, $\mathrm{Tr}$ is the trace of a matrix, and the cross-correlation matrix between PCs $Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \in \mathbb{R}^{k_i \times k_j}$ is given by:

$$
\begin{split}
Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) & = Cor(\mathbf{T}_{i} \mathbf{V}_{i}^{\top} \mathrm{diag}(\lambda_i)^{-1/2}, \mathbf{T}_{j} \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2}) \\
& = \mathrm{diag}(\lambda_i)^{-1/2} \mathbf{V}_{i} (\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1}) \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2},
\end{split}
$$

where $\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1} \in \mathbb{R}^{p_i \times p_j}$ is the cross-correlation matrix between the predicted expression levels of genes $i$ and $j$, and columns of $\mathbf{V}_{i}$ and scalars $\lambda_i$ are the eigenvectors and eigenvalues of $\mathbf{T}_{i}$, respectively.
S-MultiXcan keeps only the top eigenvectors using a condition number threshold of $\frac{\max(\lambda_i)}{\lambda_i} < 30$.
To estimate the correlation of predicted expression levels for genes $i$ in tissue $k$ and gene $j$ in tissue $l$, $(\mathbf{t}_k^i, \mathbf{t}_l^j)$ ($\mathbf{t}_k^i$ is the $k$th column of $\mathbf{T}_{i}$), we used (Zhu et al., 2019):

$$
\begin{split}
\frac{(\mathbf{T}_{i}^{\top} \mathbf{T}_{j})_{kl}}{n-1} & = Cor(\mathbf{t}_k^i, \mathbf{t}_l^j) \\
& = \frac{ Cov(\mathbf{t}_k, \mathbf{t}_l) } { \sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ Cov(\sum_{a \in \mathrm{model}_k} w_a^k X_a, \sum_{b \in \mathrm{model}_l} w_b^l X_b) }  {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l}} w_a^k w_b^l Cov(X_a, X_b)} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l}} w_a^k w_b^l \Gamma_{ab}} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} },
\end{split}
$$

where $X_a$ is the genotype of SNP $a$, $w_a^k$ is the weight of SNP $a$ for gene expression prediction in the tissue model $k$, and $\Gamma = \widehat{\mathrm{var}}(\mathbf{X}) = (\mathbf{X} - \bar{\mathbf{X}})^{\top} (\mathbf{X} - \bar{\mathbf{X}}) / (n-1)$ is the genotype covariance matrix using GTEx v8 as the reference panel, which is the same used in all TWAS methods described here.
The variance of the predicted expression values of gene $i$ in tissue $k$ is estimated as (Gamazon et al., 2018):

$$
\begin{split}
\widehat{\mathrm{var}}(\mathbf{t}_k^i) & = (\mathbf{W}^k)^\top \Gamma^k \mathbf{W}^k \\
& = \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_k}} w_a^k w_b^k \Gamma_{ab}^k.
\end{split}
$$

Since we utilized the MultiXcan regression model (Equation (1)), matrix $\mathbf{R}$ serves as an approximation of gene correlations in S-MultiXcan.
As previously discussed, S-MultiXcan estimates the joint regression parameters in MultiXcan by utilizing the marginal regression estimates from S-PrediXcan in Equation (2) with certain simplifying assumptions and distinct genotype covariance matrices.
This complexity makes it challenging to derive an S-MultiXcan-specific solution for computing matrix $\mathbf{R}$.
To address this issue, we opted to utilize a submatrix $\mathbf{R}_{\ell}$ that corresponds only to genes included in latent variable (LV) $\ell$ (the top 1% of genes), rather than the entire matrix $\mathbf{R}$.
This simplification is considered conservative, as it takes into account correlations for only the top genes.
Our simulations (see Supplementary Note 1) demonstrate that the model is reasonably well-calibrated and can effectively adjust for LVs containing adjacent and highly correlated genes at the top (e.g., Figure 1).
However, the simulation also identified 127 LVs where the model was not well-calibrated (e.g., Figure 2).
This discrepancy can be attributed to challenges in accurately computing a gene correlation matrix, leading us to exclude these LVs from our primary analyses.

In Equation (@eq:reg:corr_genes), for each gene, we only considered tissue models present in S-PrediXcan results, as well as SNPs present in GWAS used as input for the TWAS approaches.
This is necessary to obtain more accurate correlation estimates (Battle et al., 2018).
Therefore, we computed different correlation matrices for PhenomeXcan and eMERGE.
In PhenomeXcan, most of the GWAS (4,049) were obtained from the UK Biobank using the same pipeline and including the same set of SNPs, so a single correlation matrix was used for this set.
For the rest, we used a single correlation matrix for each group of traits that shared the same or most of the SNPs.

$$
\text{Equation (@eq:reg:corr_genes)}: \text{Correlation matrix computation for genes}
$$

We ran our regression model for all 987 LVs across the 4,091 traits in PhenomeXcan.
For replication, we ran the model in the 309 phecodes in eMERGE.
We adjusted the $p$-values using the Benjamini-Hochberg procedure.


### LV-based drug repurposing approach {#sec:methods:drug}

For the drug-disease prediction, we developed an LV-based method inspired by a drug repositioning framework previously utilized for psychiatric traits (Gandal et al., 2018), where individual genes associated with a trait exhibit an inverse correlation with drug expression profiles.
Our LV-based method was compared to the single-gene approach described in a study by Subramanian et al.
(2017).
In the single-gene method, a drug-disease score was computed by multiplying each set of signed z-scores from S-PrediXcan in tissue $t$, denoted as $\mathbf{M}^t$, with another set of signed z-scores from transcriptional responses profiled in LINCS L1000 (Subramanian et al., 2017), represented as $\mathbf{L}^{c \times m}$ (for $c$ compounds).
Here, $\mathbf{M}^t$ indicates whether a higher or lower predicted expression of a gene is linked to disease risk, while $\mathbf{L}$ signifies whether a drug enhances or diminishes the expression of a gene.
These matrices were multiplied to generate a score for a drug-disease pair.
The resulting product was denoted as $\mathbf{D}^{t,k}=-1 \cdot \mathbf{M}^{t,k} \mathbf{L}^\top$, where $k$ denotes the number of most significant gene associations in $\mathbf{M}^t$ for each trait.
Following the suggestion in the study by Gandal et al.
(2018), $k$ could encompass all genes or the top 50, 100, 250, and 500; subsequently, score ranks were averaged across all $k$ to yield $\mathbf{D}^t$.
Ultimately, for each drug-disease pair, the maximum prediction score across all tissues was determined as $\mathbf{D}_{ij} = \max \{ \mathbf{D}_{ij}^t \mid \forall t \}$.


The same procedure was utilized for the latent variable (LV)-based approach, in which we projected the matrices $\mathbf{M}^{t}$ and $\mathbf{L}$ into the gene module latent space using Equation (@eq:proj).
This projection resulted in $\hat{\mathbf{M}}^{t}$ and $\hat{\mathbf{L}}^{l \times c}$, respectively.
Finally, we calculated $\mathbf{D}^{t,k}=-1 \cdot \hat{\mathbf{L}}^{\top} \hat{\mathbf{M}}^{t,k}$, where in this scenario $k$ could represent all LVs or the top 5, 10, 25, and 50, considering that we have approximately an order of magnitude fewer LVs than genes. 

$$
\begin{align*}
\text{Equation (@eq:proj):} & \text{Projection of matrices $\mathbf{M}^{t}$ and $\mathbf{L}$ into gene module latent space.} \\
\end{align*}
$$


Since the gold standard of drug-disease medical indications is described with Disease Ontology IDs (DOID) [@doi:10.1093/nar/gky1032], we mapped PhenomeXcan traits to the Experimental Factor Ontology [@doi:10.1093/bioinformatics/btq099] using [@url:https://github.com/EBISPOT/EFO-UKB-mappings], and then to DOID.


### Consensus clustering of traits {#sec:methods:clustering}

We performed two preprocessing steps on the S-MultiXcan results before the cluster analysis.
First, we combined results in $\mathbf{M}$ (with $p$-values converted to $z$-scores, as described before) for traits that mapped to the same Experimental Factor Ontology (EFO) [@doi:10.1093/bioinformatics/btq099] term using the Stouffer's method:

$$
\sum w_i M_{ij} / \sqrt{\sum w_i^2}
$$

where $w_i$ is a weight based on the GWAS sample size for trait $i$, and $M_{ij}$ is the $z$-score for gene $j$.
Second, we divided all $z$-scores for each trait $i$ by their sum to reduce the effect of highly polygenic traits:

$$
M_{ij} / \sum M_{ij}
$$

Finally, we projected this data matrix using Equation (@eq:proj), obtaining $\hat{\mathbf{M}}$ with $n$=3,752 traits and $l$=987 LVs as the input of our clustering pipeline.


A partitioning of the estimated matrix M hat with n traits into k clusters is represented as a label vector Ï€ âˆˆ â„•â¿.
Consensus clustering approaches consist of two steps: 1) the generation of an ensemble Î  with r partitions of the dataset: Î ={Ï€â‚, Ï€â‚‚, ..., Ï€áµ£}, and 2) the combination of the ensemble into a consolidated solution defined as:

$$
\pi^* = \mathrm{arg}\,\underset{\hat{\pi}}{\max} Q(\{ \lvert \mathcal{L}^i \lvert \phi(\hat{\pi}_{\mathcal{L}^i}, \pi_{i \mathcal{L}^i}) \mid i \in \{1,\ldots,r\} \}),
$$ {#eq:consensus:obj_func}

where ð“›â± is a set of data indices with known cluster labels for partition i, Ï†: â„•â¿ Ã— â„•â¿ â†’ â„ is a function that measures the similarity between two partitions, and Q is a measure of central tendency, such as the mean or median.
We used the adjusted Rand index (ARI) for Ï† and the median for Q.
To obtain Ï€^*, we define a consensus function Î“: â„•â¿Ë£Ê³ â†’ â„•â¿ with Î  as the input.
We used consensus functions based on the evidence accumulation clustering (EAC) paradigm, where Î  is first transformed into a distance matrix Dáµ¢â±¼ = dáµ¢â±¼ / r, where dáµ¢â±¼ is the number of times traits i and j were grouped in different clusters across all r partitions in Î .
Then, Î“ can be any similarity-based clustering algorithm, which is applied on D to derive the final partition Ï€^*.


For the ensemble generation step, we utilized various algorithms to create a highly diverse set of partitions (see Figure 1) since diversity is a crucial property for ensembles (Sokolova et al., 2016; He et al., 2011; Liu et al., 2014).
We employed three data representations: the raw dataset, its projection into the top 50 principal components, and the embedding learned by UMAP (McInnes et al., 2018) using 50 components.
For each of these, we applied five clustering algorithms covering a wide range of different assumptions on the data structure: k-means (Arthur and Vassilvitskii, 2007), spectral clustering (Ng et al., 2001), a Gaussian mixture model (GMM), hierarchical clustering, and DBSCAN (Ester et al., 1996). 

$$
\text{Equation (1): } k
$$

For k-means, spectral clustering, and GMM, we specified a range of k between 2 and sqrt(n) â‰ˆ 60, and for each k, we generated five partitions using random seeds.
For hierarchical clustering, for each k, we generated four partitions using common linkage criteria: ward, complete, average, and single.
For DBSCAN, we combined different ranges for parameters Îµ (the maximum distance between two data points to be considered part of the same neighborhood) and minPts (the minimum number of data points in a neighborhood for a data point to be considered a core point), based on the procedure in (Deng et al., 2018).
Specifically, we used minPts values from 2 to 125.
For each data representation (raw, PCA, and UMAP), we determined a plausible range of Îµ values by observing the distribution of the mean distance of the minPts-nearest neighbors across all data points. 

$$
\text{Equation (2): } \epsilon
$$

Since some combinations of minPts and Îµ might not produce a meaningful partition (for instance, when all points are detected as noisy or only one cluster is found), we resampled partitions generated by DBSCAN to ensure an equal representation of this algorithm in the ensemble.
This procedure generated a final ensemble of 4,428 partitions of 3,752 traits.


Finally, we used spectral clustering on matrix $\mathbf{D}$ to derive the final consensus partitions.
Matrix $\mathbf{D}$ was first transformed into a similarity matrix by applying a Radial Basis Function (RBF) kernel $\mathrm{exp}(-\gamma \mathbf{D}^2)$ using four different values for $\gamma$ that were empirically determined to work best.
Therefore, for each value of $k$ between 2 and 60, we derived four consensus partitions and selected the one that maximized Equation (1).
We further filtered this set of 59 solutions to keep only those with an ensemble agreement larger than the 75th percentile (Figure 1), leaving a total of 15 final consensus partitions shown in Figure 2. 

$$
\mathrm{exp}(-\gamma \mathbf{D}^2) {#eq:rbf_kernel}
$$

The input data in our clustering pipeline undergoes several linear and nonlinear transformations, including Principal Component Analysis (PCA), Uniform Manifold Approximation and Projection (UMAP), and the ensemble transformation using the Ensemble Agglomerative Clustering (EAC) paradigm (distance matrix $\mathbf{D}$).
Although consensus clustering has clear advantages for biological data (Kapp and Tibshirani, 2016), this set of data transformations complicates the interpretation of results.
To circumvent this, we used a supervised learning approach to detect which gene modules/Latent Variables (LVs) are the most important for each cluster of traits (Figure 1b).
Note that we did not use this supervised model for prediction but only to learn which features (LVs) were most discriminative for each cluster.
For this, we used the highest resolution partition ($k$=29, although any could be used) to train a decision tree model using each of the clusters as labels and the projected data $\hat{\mathbf{M}}$ as the training samples. 

$$
\text{Equation (1)}
$$

For each $k$, we built a set of binary labels with the current cluster's traits as the positive class and the rest of the traits as the negative class.
Then, we selected the LV in the root node of the trained model only if its threshold was positive and larger than one standard deviation.
Next, we removed this LV from $\hat{\mathbf{M}}$ (regardless of being previously selected or not) and trained the model again.
We repeated this procedure 20 times to extract the top 20 LVs that better discriminate traits in a cluster from the rest.

In [Supplementary Note 2](#sm:clustering:null_sim), we performed several analyses under a null hypothesis of no structure in the data to verify that the clustering results detected by this pipeline were real.


### CRISPR-Cas9 screening {#sec:methods:crispr}

**Cell culture.** HepG2 cells were obtained from ATCC (ATCCÂ® HB-8065â„¢) and were cultured in Eagle's Minimum Essential Medium with L-Glutamine (EMEM, Cat.
112-018-101, Quality Biology) supplemented with 10% Fetal Bovine Serum (FBS, Gibco, Cat.16000-044) and 1% Penicillin-Streptomycin (Pen/Strep, Gibco, Cat.15140-122).
The cells were maintained at 37Â°C in a humidity-controlled incubator with 5% CO2 and were kept at a density not exceeding 80% confluency in Collagen-I coated flasks.

$$
\begin{align*}
&\text{Where:} \\
&\text{EMEM} = \text{Eagle's Minimum Essential Medium} \\
&\text{FBS} = \text{Fetal Bovine Serum} \\
&\text{Pen/Strep} = \text{Penicillin-Streptomycin}
\end{align*}
$$

**Genome-wide lentiviral pooled CRISPR-Cas9 library.** The third generation of the lentiviral Broad GPP genome-wide Human Brunello CRISPR knockout Pooled library, obtained from Addgene (Cat.
73179-LV) courtesy of David Root and John Doench, was utilized for transduction of HepG2 cells.
This library comprises 76,441 sgRNAs targeting 19,114 genes in the human genome, with an average of 4 sgRNAs per gene.
Each 20 nucleotide sgRNA sequence was integrated into the lentiCRIS-PRv2 backbone between the U6 promoter and gRNA scaffold.
Through cell transduction, lentiviral vectors encoding Cas9 delivered the sgRNA cassette-containing plasmids into cells during replication.
Cells that were not successfully transduced were eliminated via puromycin selection.

$$
\text{Symbols:}
\begin{align*}
& \text{sgRNA} \text{ - single guide RNA} \\
& \text{nt} \text{ - nucleotide} \\
& \text{Cas9} \text{ - CRISPR-associated protein 9}
\end{align*}
$$

**Lentiviral titer determination.** No-spin lentiviral transduction was used for the screen.
Approximately 2.5 million cells were seeded in a Collagen-I coated 6-well plate, with each well containing 8ug/ml of polybrene (Millipore Sigma, Cat.
TR-1003 G) and a different titrated virus volume (e.g., 0, 50, 100, 200, 250, and 400ul).
EMEM complete media was added to reach a final volume of 1.24ml.
Sixteen to eighteen hours post-transduction, the virus/polybrene-containing media was removed from each well.
Cells were washed twice with 1x DPBS and fresh EMEM was added.
At 24 hours, cells in each well were trypsinized, diluted (e.g., 1:10), and seeded in pairs of wells in 6-well plates.
At 60 hours post-transduction, the cell media in each well was replaced with fresh EMEM.
One well out of the pair was treated with 2ug/ml puromycin (Gibco, Cat.
A1113803).
Two to five days after puromycin selection, if the well with 0 virus treated with puromycin showed no cell survival, cells in both wells with and without puromycin were collected and counted for viability.
The Percentage of Infection (PI%) was calculated by comparing the cell numbers with and without puromycin selection within each pair.
According to Poisson's distribution theory, a transduction efficiency (PI%) between 30-50% corresponds to a Multiplicity of Infection (MOI) of approximately 0.35-0.70.
At an MOI close to 0.3, around 25% of cells are infected, and most of those infected cells are expected to have only one copy of the virus.
Therefore, a virus volume of 120ul, which yielded 30-40% transduction efficiency, was selected for further large-scale viral transduction.

$$
\text{Definitions:} \\
\text{PI% - Percentage of Infection} \\
\text{MOI - Multiplicity of Infection} \\
$$

Lentiviral transduction was conducted in HepG2 cells using the Brunello CRISPR knockout pooled library to ensure a coverage of at least 500 cells per single guide RNA (sgRNA).
An MOI between 0.3-0.4 was maintained to guarantee that 95% of infected cells received only one viral particle per cell.
Approximately 200 million cells were used for the screen.
The transduction process followed a similar protocol as previously described.
Specifically, 2.5 million cells were seeded in each well of 14 6-well plates with 8ug/ml of polybrene.
Subsequently, 120ul of the virus was added to each experimental well.
After 18 hours post-transduction, the virus/polybrene mix medium was removed, and cells from each well were collected, counted, and pooled into T175 flasks.
At 60 hours post-transduction, 2ug/ml of puromycin was added to each flask.
The medium was changed every two days with fresh EMEM containing 2ug/ml puromycin.
Seven days after puromycin selection, cells were collected, pooled, counted, and replated.

**Fluorescent dye staining.** Nine days after puromycin selection, cells were divided into two groups.
Twenty to thirty million cells were collected as the Unsorted Control.
The cell pellet was centrifuged at 500 x g for 5 minutes at 4Â°C.
The dry pellet was stored at -80Â°C for subsequent genomic DNA isolation.
The remaining cells (approximately 200 million) were cultured in 100 mm dishes and stained with a fluorescent dye (LipidSpotTM 488, Biotium, Cat.
70065-T).
Briefly, LipidSpot 488 was diluted to 1:100 with DPBS.
Four milliliters of staining solution were added to each dish and incubated at 37Â°C for 30 minutes.
Cell images were captured using a fluorescent microscope EVOS for GFP signal detection (Figure 1).

**Fluorescence-activated cell sorting (FACS).** Cells were immediately collected into 50 mL tubes (from this point on, keep cells cold) and spun at 500 x g for 5 min at 4Â°C.
After a DPBS wash, cell pellets were resuspended with FACS Sorting Buffer (1x DPBS without Ca2+/Mg2+, 2.5 mM EDTA, 25 mM HEPES, 1% BSA).
The solution was filter-sterilized and kept at 4Â°C, with gentle pipetting to ensure single cells.
The cell solution was then filtered through a cell strainer (Falcon, Cat.
352235) and kept on ice, protected from light.
Collected cells were sorted on FACSJazz using a 100 Âµm nozzle for sorting.
Approximately 20% of each GFP-High and GFP-Low population (Figure 2) were collected into 15 mL tubes.
After sorting, cells were immediately spun down, and the pellets were stored at -80Â°C for further isolation of genomic DNA.

$$
\text{Symbols:} \\
\text{FACS} = \text{Fluorescence-activated cell sorting} \\
\text{DPBS} = \text{Dulbecco's phosphate-buffered saline} \\
\text{EDTA} = \text{Ethylenediaminetetraacetic acid} \\
\text{HEPES} = \text{4-(2-hydroxyethyl)-1-piperazineethanesulfonic acid} \\
\text{BSA} = \text{Bovine serum albumin} \\
\text{GFP} = \text{Green fluorescent protein}
$$

**Genomic DNA isolation and verification.** Three conditions of genomic DNA (Un-Sorted Control, lentiV2 GFP-High, and lentiV2 GFP-Low) were extracted using the QIAamp DNA Blood Mini Kit (Qiagen, Cat.51104), followed by UV spectroscopy (Nanodrop) to assess the quality and quantity of the gDNA.
A total of 80-160 Î¼g of gDNA was isolated for each condition.
The sgRNA cassette and lentiviral specific transgene in the isolated gDNA were verified through polymerase chain reaction (PCR) (Figure 1).

$$
\text{Figure 1: PCR verification of sgRNA cassette and lentiviral specific transgene in isolated gDNA}
$$

**Illumina libraries generation and sequencing.** 

The fragment containing the sgRNA cassette was amplified using P5/P7 primers, as indicated in the study by Smith et al.
(2016), and primer sequences were adapted from the Broad Institute protocol (Figure 1).
A stagger sequence (0-8nt) was included in P5, and an 8bp uniquely barcoded sequence was included in P7.
Primers were synthesized through Integrated DNA Technologies (IDT), and each primer was PAGE purified.
Thirty-two PCR reactions were set up for each condition.
Each 100 Î¼l PCR reaction consisted of approximately 5 Î¼g of gDNA, 5 Î¼l of each 10 Î¼M P5 and P7 primers.
ExTaq DNA Polymerase (TaKaRa, Cat.
RR001A) was used to amplify the amplicon.
The PCR thermal cycler parameters were set as follows: an initial denaturation at 95Â°C for 1 minute, followed by 24 cycles of denaturation at 94Â°C for 30 seconds, annealing at 52.5Â°C for 30 seconds, extension at 72Â°C for 30 seconds, and a final elongation at 72Â°C for 10 minutes.
PCR products of 285-293 bp were expected (Figure 2A). 

PCR products within the same condition were pooled and purified using SPRIselect beads (Beckman Coulter, Cat.
B23318).
The purified Illumina libraries were quantitated on Qubit, and the quality of the library was analyzed on a Bioanalyzer using a High Sensitivity DNA Chip.
A single approximate 285 bp peak was expected (Figure 2B).
The final Illumina library samples were sequenced on a NovaSeq 6000.
Samples were pooled and loaded on an SP flow cell, along with a 20% PhiX control v3 library spike-in. 

$$
\text{Figure 1: Primer sequences used for amplification.}
$$

$$
\text{Figure 2: Expected PCR product sizes.}
$$


## Data availability

All the main datasets generated in this study are available at [https://doi.org/10.5281/zenodo.8071382](https://doi.org/10.5281/zenodo.8071382) [@doi:10.5281/zenodo.8071382] and the GitHub repository [https://github.com/greenelab/phenoplier](https://github.com/greenelab/phenoplier).

The main input datasets used are TWAS from PhenomeXcan [@doi:10.1126/sciadv.aba2083] for 4,091 traits and from the Electronic Medical Records and Genomics (eMERGE) network phase III [@doi:10.1101/2021.10.21.21265225] for 309 traits; transcriptional responses to small molecule perturbations from LINCS L1000 [@doi:10.1016/j.cell.2017.10.049] that were further preprocessed and mapped to DrugBank IDs from [@doi:10.5281/zenodo.47223]; latent space/gene module models from MultiPLIER [@doi:10.1016/j.cels.2019.04.003].

The data utilized from PhenomeXcan, LINCS L1000, and MultiPLIER are publicly available.
All significant results reported for the eMERGE and Penn Medicine BioBank (PMBB) phenome-wide TWAS are contained in a previous publication (Smith et al., 2021).
The individual-level PMBB raw datasets cannot be made publicly available due to institutional privacy policy.
Researchers interested in accessing the data should contact Penn Medicine Biobank for requests.
The eMERGE network phase III data is available on dbGAP (Accession: phs001584.v2.p2). 

$$
\text{PhenomeXcan} - \text{Phenome-wide association studies}
$$ {#id}

$$
\text{LINCS L1000} - \text{Library of Integrated Network-based Cellular Signatures}
$$ {#id}

$$
\text{MultiPLIER} - \text{Multi-omic Factor Analysis}
$$ {#id}


## Code availability

The code necessary to reproduce all the analyses in this work is available at [https://doi.org/10.5281/zenodo.8071382](https://doi.org/10.5281/zenodo.8071382) [@doi:10.5281/zenodo.8071382] and the GitHub repository [https://github.com/greenelab/phenoplier](https://github.com/greenelab/phenoplier).

For the CRISPR screening, FlowJo v10.7 and FACS Jazz Software v1.1 were utilized.
Data analysis was conducted using Python 3.8 and R 3.6, along with various computational packages.
The primary Python packages included Jupyter Lab (2.2), pandas (1.1), matplotlib (3.3), seaborn (0.11), numpy (1.19), scipy (1.5), scikit-learn (0.23), and umap-learn (0.4).
In R, the main packages used were Bioconductor (3.10), clusterProfiler (3.14), clustree (0.4), and fgsea (1.17).
Additionally, several scripts and notebooks were developed and made available under an open-source license.
Detailed documentation of all analysis steps was provided, along with a Docker image for replicating the runtime environment and a demo for quick testing of the methods on real data. 

$$ FlowJo v10.7, FACS Jazz Software v1.1 $${#id1}

$$ Python 3.8, R 3.6, Jupyter Lab (2.2), pandas (1.1), matplotlib (3.3), seaborn (0.11), numpy (1.19), scipy (1.5), scikit-learn (0.23), umap-learn (0.4) $${#id2}

$$ R, Bioconductor (3.10), clusterProfiler (3.14), clustree (0.4), fgsea (1.17) $${#id3}
